



<!doctype html>
<html lang="zh-Hant" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
        <meta name="author" content="10程式中">
      
      
        <meta name="lang:clipboard.copy" content="複製">
      
        <meta name="lang:clipboard.copied" content="已複製">
      
        <meta name="lang:search.language" content="ja">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="沒有符合的項目">
      
        <meta name="lang:search.result.one" content="找到 1 個符合的項目">
      
        <meta name="lang:search.result.other" content="找到 # 個符合的項目">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.0">
    
    
      
        <title>[Day 8] 線性迴歸 (Linear Regression) - 全民瘋AI系列 [經典機器學習]</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.0284f74d.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.01803549.css">
      
      
        
        
        <meta name="theme-color" content="#795548">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="brown" data-md-color-accent="deep-orange">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#day-8-linear-regression" tabindex="1" class="md-skip">
        跳轉到
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="全民瘋AI系列 [經典機器學習]" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              全民瘋AI系列 [經典機器學習]
            </span>
            <span class="md-header-nav__topic">
              
                [Day 8] 線性迴歸 (Linear Regression)
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜尋" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            打字進行搜尋
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/andy6804tw/2021-13th-ironman" title="前往倉庫" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="全民瘋AI系列 [經典機器學習]" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    全民瘋AI系列 [經典機器學習]
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/andy6804tw/2021-13th-ironman" title="前往倉庫" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      第一部分 AI基礎概念
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        第一部分 AI基礎概念
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../1.全民瘋AI系列2.0目標介紹/" title="[Day 1] 目標介紹" class="md-nav__link">
      [Day 1] 目標介紹
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../2.快來探索AI的世界/" title="[Day 2] 快來探索AI的世界" class="md-nav__link">
      [Day 2] 快來探索AI的世界
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.你真了解資料嗎試試看視覺化分析吧/" title="[Day 3] 你真了解資料嗎?試試看視覺化分析吧!" class="md-nav__link">
      [Day 3] 你真了解資料嗎?試試看視覺化分析吧!
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../4.咱們一起做資料清理和前處理/" title="[Day 4] 咱們一起做資料清理和前處理" class="md-nav__link">
      [Day 4] 咱們一起做資料清理和前處理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../5.機器學習大補帖/" title="[Day 5] 機器學習大補帖" class="md-nav__link">
      [Day 5] 機器學習大補帖
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      第二部分 機器學習入門
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        第二部分 機器學習入門
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../6.非監督式學習k-means分群/" title="[Day 6] 非監督式學習 K-means 分群" class="md-nav__link">
      [Day 6] 非監督式學習 K-means 分群
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../7.非監督式學習-降維/" title="[Day 7] 非監督式學習-降維" class="md-nav__link">
      [Day 7] 非監督式學習-降維
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        [Day 8] 線性迴歸 (Linear Regression)
      </label>
    
    <a href="./" title="[Day 8] 線性迴歸 (Linear Regression)" class="md-nav__link md-nav__link--active">
      [Day 8] 線性迴歸 (Linear Regression)
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">本頁目錄</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="認識線性迴歸" class="md-nav__link">
    認識線性迴歸
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="兩種求解方法" class="md-nav__link">
    兩種求解方法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" title="小試身手" class="md-nav__link">
    小試身手
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" title="範例程式 (房價預測)" class="md-nav__link">
    範例程式 (房價預測)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" title="手刻線性迴歸" class="md-nav__link">
    手刻線性迴歸
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sklearn-linearregression" title="使用 Sklearn LinearRegression" class="md-nav__link">
    使用 Sklearn LinearRegression
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" title="多項式的迴歸模型" class="md-nav__link">
    多項式的迴歸模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" title="線性模型的擴展" class="md-nav__link">
    線性模型的擴展
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sklearn" title="Sklearn 實作多項式迴歸" class="md-nav__link">
    Sklearn 實作多項式迴歸
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent" title="Gradient descent (梯度下降法)" class="md-nav__link">
    Gradient descent (梯度下降法)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sklearn-sgdregressor" title="使用 Sklearn SGDRegressor" class="md-nav__link">
    使用 Sklearn SGDRegressor
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../9.邏輯迴歸/" title="[Day 9] 邏輯迴歸 (Logistic Regression)" class="md-nav__link">
      [Day 9] 邏輯迴歸 (Logistic Regression)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../10.KNN/" title="[Day 10] 近朱者赤，近墨者黑 - KNN" class="md-nav__link">
      [Day 10] 近朱者赤，近墨者黑 - KNN
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../11.SVM/" title="[Day 11] 核模型 - 支持向量機 (SVM)" class="md-nav__link">
      [Day 11] 核模型 - 支持向量機 (SVM)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../12.決策樹/" title="[Day 12] 決策樹 (Decision tree)" class="md-nav__link">
      [Day 12] 決策樹 (Decision tree)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../13.整體學習/" title="[Day 13] 整體學習 (Ensemble Learning)" class="md-nav__link">
      [Day 13] 整體學習 (Ensemble Learning)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../14.隨機森林/" title="[Day 14] 多棵決策樹更厲害：隨機森林 (Random forest)" class="md-nav__link">
      [Day 14] 多棵決策樹更厲害：隨機森林 (Random forest)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../15.XGBoost/" title="[Day 15] 機器學習常勝軍 - XGBoost" class="md-nav__link">
      [Day 15] 機器學習常勝軍 - XGBoost
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../16.Stacking/" title="[Day 16] 每個模型我全都要 - 堆疊法 (Stacking)" class="md-nav__link">
      [Day 16] 每個模型我全都要 - 堆疊法 (Stacking)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../17.LightGBM/" title="[Day 17] 輕量化的梯度提升機 - LightGBM" class="md-nav__link">
      [Day 17] 輕量化的梯度提升機 - LightGBM
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../18.CatBoost/" title="[Day 18] 機器學習 boosting 神器 - CatBoost" class="md-nav__link">
      [Day 18] 機器學習 boosting 神器 - CatBoost
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      第三部分 進階概念與應用
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        第三部分 進階概念與應用
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../19.AutoML/" title="[Day 19] 自動化機器學習 - AutoML" class="md-nav__link">
      [Day 19] 自動化機器學習 - AutoML
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../20.Auto-Sklearn/" title="[Day 20] 機器學習金手指 - Auto-sklearn" class="md-nav__link">
      [Day 20] 機器學習金手指 - Auto-sklearn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../21.Optuna/" title="[Day 21] 調整模型超參數利器 - Optuna" class="md-nav__link">
      [Day 21] 調整模型超參數利器 - Optuna
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../22.Plotly-Express/" title="[Day 22] Python 視覺化解釋數據 - Plotly Express" class="md-nav__link">
      [Day 22] Python 視覺化解釋數據 - Plotly Express
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../23.資料分布與離群值處理/" title="[Day 23] 資料分布與離群值處理" class="md-nav__link">
      [Day 23] 資料分布與離群值處理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../24.不能忽視的過擬合與欠擬合/" title="[Day 24] 機器學習 - 不能忽視的過擬合與欠擬合" class="md-nav__link">
      [Day 24] 機器學習 - 不能忽視的過擬合與欠擬合
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../25.交叉驗證 Cross-Validation 簡介/" title="[Day 25] 交叉驗證 Cross-Validation 簡介" class="md-nav__link">
      [Day 25] 交叉驗證 Cross-Validation 簡介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../26.交叉驗證 K-Fold Cross-Validation/" title="[Day 26] 交叉驗證 K-Fold Cross-Validation" class="md-nav__link">
      [Day 26] 交叉驗證 K-Fold Cross-Validation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../27.機器學習常犯錯的十件事/" title="[Day 27] 機器學習常犯錯的十件事" class="md-nav__link">
      [Day 27] 機器學習常犯錯的十件事
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../28.儲存訓練好的模型/" title="[Day 28] 儲存訓練好的模型" class="md-nav__link">
      [Day 28] 儲存訓練好的模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../29.使用Python-Flask架設API吧/" title="[Day 29] 使用 Python Flask 架設 API 吧！" class="md-nav__link">
      [Day 29] 使用 Python Flask 架設 API 吧！
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../30.使用 Heroku 部署機器學習 API/" title="[Day 30] 使用 Heroku 部署機器學習 API" class="md-nav__link">
      [Day 30] 使用 Heroku 部署機器學習 API
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">本頁目錄</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="認識線性迴歸" class="md-nav__link">
    認識線性迴歸
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="兩種求解方法" class="md-nav__link">
    兩種求解方法
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" title="小試身手" class="md-nav__link">
    小試身手
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" title="範例程式 (房價預測)" class="md-nav__link">
    範例程式 (房價預測)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" title="手刻線性迴歸" class="md-nav__link">
    手刻線性迴歸
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sklearn-linearregression" title="使用 Sklearn LinearRegression" class="md-nav__link">
    使用 Sklearn LinearRegression
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" title="多項式的迴歸模型" class="md-nav__link">
    多項式的迴歸模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" title="線性模型的擴展" class="md-nav__link">
    線性模型的擴展
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sklearn" title="Sklearn 實作多項式迴歸" class="md-nav__link">
    Sklearn 實作多項式迴歸
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent" title="Gradient descent (梯度下降法)" class="md-nav__link">
    Gradient descent (梯度下降法)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sklearn-sgdregressor" title="使用 Sklearn SGDRegressor" class="md-nav__link">
    使用 Sklearn SGDRegressor
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="day-8-linear-regression">[Day 8] 線性迴歸 (Linear Regression)</h1>
<p>## 今日學習目標
- 認識線性迴歸
    - 透過機器學習來找出一條函式，來最佳化模型
    - 兩種求解方法
- 線性迴歸程式手把手
    - 簡單線性迴歸、多元迴歸、非線性迴歸</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/L0X1ppgWwAk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>範例程式：<a href="https://colab.research.google.com/github/andy6804tw/2021-13th-ironman/blob/main/docs/8.線性迴歸/8.線性迴歸.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<h2 id="_1">認識線性迴歸</h2>
<p>線性迴歸是統計上在找多個自變數和依變數之間的關係所建出來的模型。只有一個自變數(x)和一個依變數(y)的情形稱為簡單線性迴歸大於一個自變數(x<sub>1</sub>,x<sub>2</sub>,...)的情形稱為多元迴歸。</p>
<p>一個簡單線性迴歸: y=ax+b，其中 b：截距(Intercept)，a：斜率(Slope) 為 x 變動一個單位 y 變動的量，如下圖:</p>
<p><img alt="" src="image/img8-1.png" /></p>
<p>迴歸分析的目標函數或稱損失函數(loss function)就是希望找到的模型最終的殘差越小越好，來找參數 a 和 b。</p>
<h2 id="_2">兩種求解方法</h2>
<p>線性模型最常見的解法有兩種，分別為 Closed-form (閉式解) 與梯度下降 (Gradient descent)。當特徵少時使用 Closed-form 較為適合，使用下面公式來求出 θ 值。我們又可以說線性模型的最小平方法的解即為 Closed-form。若當是複雜的問題時 Gradient descen 較能解決，其原因是大部分的問題其實是沒有公式解的。我們只能求出一個函數 f(x) 使其誤差最小越好。</p>
<ul>
<li>Closed-form</li>
</ul>
<p><img alt="" src="image/img8-2.png" /></p>
<ul>
<li>Gradient descent</li>
</ul>
<p><img alt="" src="image/img8-3.png" /></p>
<p>## Least Square Method (最小平方法)
 假設一個地區的房價與坪數是呈線性關係，並以下圖中的三個點表示。如果我們想透過房子的坪數來預測房價，那麼我們的目標就是找到一條直線，並與座標平面上這三個點的差距越小越好。那這條直線該怎麼找呢？首先我們隨機找一條直線，並計算這三點的 loss。損失函數可以自己定義，假設我們使用 MSE 均方誤差來計算。透過一系列計算我們得到一個 loss 即為 MSE 值。接著我們將這個直線稍稍的轉一個角度後又可以計算一個新的 MSE，此刻我們可以發現 MSE 值又比剛剛更小了。也就是說這一條新的直線能夠更法應出訓練集中 A、B、C 的數據點所反映的房屋坪數與房價之間的線性關係。</p>
<p><img alt="" src="image/img8-4.png" /></p>
<p>簡單來說我們在一個二維空間中，我們可以找到無數條直線。現在我們能做的事情就是從這無數條直線中選出一條最佳的當作我們的預測模型，同時它面對這三點的誤差是要最小的。因此我們的目標就是要最小化 MSE 也就是所謂的損失函數 (loss function)。所以整個線性迴歸的目標就是最小化我們的損失函數，其中一個解法就是最小平方法。因為 MSE 等於 1/n 倍的残差平方和 (RSS)，其中分母 n 為常數，不影響極小化故拿掉。因此最終的求解是滿足最小化平方和，使其最小化。經過數學推導後，簡化的公式如下：</p>
<p><img alt="" src="image/img8-2.png" /></p>
<h3 id="_3">小試身手</h3>
<p>基於上面的公式我們想找出一組參數權重 θ。也就是下圖問題中的 a (θ<sub>0</sub>)、b (θ<sub>1</sub>) 兩參數，使得平面上這三點平方和有極小值。這個函式對 θ<sub>0</sub>, θ<sub>1</sub> 偏做微分設他們為0，接著我們對方程式求解。 此函式只有極小值，因此我們得到的 θ<sub>0</sub>, θ<sub>1</sub> 最小極值的解。</p>
<p><img alt="" src="image/img8-5.png" /></p>
<h2 id="_4">範例程式 (房價預測)</h2>
<h3 id="_5">手刻線性迴歸</h3>
<p>我們透過 Sklearn 所提供的房價預測資料集進行線性迴歸模型建模，並採用最小平法。首先為了要驗證我們上面的公式，因此我們先利用 Numpy 套件自己手刻做一系列的矩陣運算求出每一項的係數與截距。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>

<span class="c1"># 載入 Sklearn 房價預測資料集 13個輸入特徵 1個輸出特徵</span>
<span class="n">boston_dataset</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="c1"># 輸入特徵共13個</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">boston_dataset</span><span class="o">.</span><span class="n">data</span>
<span class="c1"># 設定截距項 b 權重值為 1 </span>
<span class="n">b</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="c1"># 添加常數項特徵，最終有 13+1 個輸入特徵</span>
<span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
<span class="c1"># 輸出(房價)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">boston_dataset</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># 計算 Beta (@ 為 numpy 中 2-D arrays 的矩陣乘法)</span>
<span class="n">Beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">Beta</span>

<span class="c1"># MSE: 21.8948311817292</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MSE:&#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>


<p>計算出來 Beta 後我們再把所有的 X 帶入並做計算，算出來的結果 MSE 為 21.89。最後我們可以試著把 Beta 變數列印出來。總共會有 14 個參數，由 13 個輸入特徵係數與最後一項截距所組成的。</p>
<p>輸出結果：</p>
<div class="codehilite"><pre><span></span>array([-1.08011358e-01,  4.64204584e-02,  2.05586264e-02,  2.68673382e+00,
       -1.77666112e+01,  3.80986521e+00,  6.92224640e-04, -1.47556685e+00,
        3.06049479e-01, -1.23345939e-02, -9.52747232e-01,  9.31168327e-03,
       -5.24758378e-01,  3.64594884e+01])
</pre></div>


<h2 id="sklearn-linearregression">使用 Sklearn LinearRegression</h2>
<p>線性迴歸簡單來說，就是將複雜的資料數據，擬和至一條直線上，就能方便預測未來的資料。接下來我們一樣使用房價預測資料集，並使用 Sklearn 提供的 LinearRegression 來求解。</p>
<p>Parameters:
- fit_intercept: 是否有截距，如果沒有則直線過原點。</p>
<p>Attributes:
- coef_: 取得係數。
- intercept_: 取得截距。</p>
<p>Methods:
- fit: 放入X、y進行模型擬合。
- predict: 預測並回傳預測類別。
- score: R2 score 模型評估。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>

<span class="c1"># 載入 Sklearn 房價預測資料集 13個輸入特徵 1個輸出特徵</span>
<span class="n">boston_dataset</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="c1"># 輸入特徵共13個</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">boston_dataset</span><span class="o">.</span><span class="n">data</span>
<span class="c1"># 輸出(房價)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">boston_dataset</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># 訓練模型</span>
<span class="n">linearModel</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">linearModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">linearModel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 21.894831181729202</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MSE:&#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>


<p>Sklearn 的 LinearRegression 模型也是採用小平方法求解。我們可以發現其 MSE 與稍早手刻的方法相當很接近。另外 Sklearn 模型同時也提供了 <code>coef_</code> 和 <code>intercept_</code> 兩個屬性可以取得模型的特徵係數與截距。</p>
<p><img alt="" src="image/img8-6.png" /></p>
<h2 id="_6">多項式的迴歸模型</h2>
<p>對於線性迴歸來說，資料都是很均勻地分布在一條直線上，但現實的資料往往是非線性的分佈。如果我們一樣使用上述方法取得線性模型，在實際場域上預測效果可能並不大。</p>
<p><img alt="" src="image/img8-7.png" /></p>
<p>多項式迴歸中，數據不太具有線性關係，因此應尋找一些非線性曲線去擬合。對於以上的數據，原本是只有一個 x 特徵，但是我們可以建構許多新的特徵。如下圖，用一條三次曲線去擬合數據效果更好。我們將三次函數看成 ax<sup>3</sup>+bx<sup>2</sup>+cx+d。這樣就又變成解多元，其我們就是要找出 a、b、c、d 使其損失函數最小。</p>
<p><img alt="" src="image/img8-8.png" /></p>
<h3 id="_7">線性模型的擴展</h3>
<p>從上述問題中我們可以發現線性迴歸在實務上所面臨的問題。首先我們來迴顧一下稍早所提到的線性方程式，這組線性方程式說明了每個特徵 x 一次方與目標值是有一個線性的關係。</p>
<p>y = β<sub>0</sub> + β<sub>1</sub>x<sub>1</sub> + β<sub>2</sub>x<sub>2</sub> + ... + β<sub>n</sub>x<sub>n</sub></p>
<p>接著我們再來看一下另一個例子，比如說特徵 x<sub>1</sub> 與目標值存在著以下的關係。我們發現這組方程式已經不是一個線性關係了，因為他有了 x<sub>1</sub> 的二次方。</p>
<p>y = β<sub>0</sub> + β<sub>1</sub>x<sub>1</sub> + β<sub>2</sub>x<sub>1</sub><sup>2</sup></p>
<p>那麼該怎麼做我們才能又把它轉換成線性關係呢？這時候我們就可以用一個新的特徵 x<sub>2</sub>。我們讓 x<sub>2</sub> 等於 x<sub>1</sub> 的平方，這樣我們再把 x<sub>2</sub> 帶迴原方程式中。此時這兩個特徵 x<sub>1</sub> 與 x<sub>2</sub> 與目標值又迴到了線性關係。</p>
<p>Let x<sub>2</sub> = x<sub>1</sub><sup>2</sup></p>
<p>=&gt; y = β<sub>0</sub> + β<sub>1</sub>x<sub>1</sub> + β<sub>2</sub>x<sub>2</sub></p>
<p>同樣的我們再來看另一個例子。我們如果引入了 x<sub>1</sub> 的三次方的話，他的方程式如下：</p>
<p>y = β<sub>0</sub> + β<sub>1</sub>x<sub>1</sub> + β<sub>2</sub>x<sub>1</sub><sup>2</sup> + β<sub>3</sub>x<sub>1</sub><sup>3</sup></p>
<p>同理我們這時一樣可以引入新的特徵 x<sub>2</sub> 等於 x<sub>1</sub> 的二次方，以及 x<sub>3</sub> 等於 x<sub>1</sub> 的三次方。這樣經過一個轉換以後我們的 y 值與所有的特徵間依然存在著線性關係。</p>
<p>Let x<sub>2</sub> = x<sub>1</sub><sup>2</sup> and x<sub>3</sub> = x<sub>1</sub><sup>3</sup></p>
<p>=&gt; y = β<sub>0</sub> + β<sub>1</sub>x<sub>1</sub> + β<sub>2</sub>x<sub>2</sub> + β<sub>3</sub>x<sub>3</sub></p>
<p>這裡做一個小結。我們可以透過引入轉變過後的 x 作為一個新的特徵來滿足線性假設。此時的迴歸方程式就是一個多項式迴歸(polynomial regression)。</p>
<h2 id="sklearn">Sklearn 實作多項式迴歸</h2>
<p>由於 Sklearn 沒有封裝好的多項式迴歸模型可以直接呼叫。不過我們可以透過 <code>make_pipeline</code> 將 <code>PolynomialFeatures</code> 與 <code>LinearRegression</code> 封裝成一個多項式迴歸模型，並且使用者可以隨意設定 degree(次方)值。</p>
<p>我們可以對原本的特徵進行 PolynomialFeatures 構造新樣本特徵採。並將轉換後的特徵送到線性迴歸模型進行擬合。因此我們可以自定義一個 <code>PolynomialRegression()</code> 的函式，使用者可以輸入 degree 大小控制模型的強度。在這個函式中我們使用 Sklearn 的 pipeline 方法將 <code>PolynomialFeatures</code> 特徵轉換與 <code>LinearRegression</code> 線性迴歸模型封裝起來。另外以下範例是透過自訂義的 <code>make_data()</code> 函式產生一組隨機的 x 和 y。該函式中可以設定隨機資料的比數，下面程式中我們先隨機建立 100 筆數據。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn&#39;</span><span class="p">)</span>

<span class="c1"># make_pipeline是指可以將多個Sklearn的function一起執行</span>
<span class="k">def</span> <span class="nf">PolynomialRegression</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="p">),</span>
                         <span class="n">LinearRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>

<span class="c1"># 隨機定義新的x,y值</span>
<span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">err</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">rseed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
    <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">rseed</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mi">10</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">+</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">err</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">y</span><span class="o">+=</span><span class="n">err</span><span class="o">*</span><span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_data</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p>訓練資料與測試資料都建立完成後。我們就可以將訓練資料丟入建立好的 <code>PolynomialRegression()</code> 並進行數據擬合。下面範例程式中我們演示 degree 等於 1、3、9，並來查看隨著次方數的增長對於模型的擬合程度的影響。</p>
<div class="codehilite"><pre><span></span><span class="c1"># 測試資料集</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1.1</span><span class="p">,</span><span class="mi">500</span><span class="p">)[:,</span><span class="kc">None</span><span class="p">]</span>
<span class="c1"># 繪製真實答案的分佈</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span><span class="n">y</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="c1"># 測試 1,3,7 的degree</span>
<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">]:</span>
    <span class="n">y_test</span><span class="o">=</span><span class="n">PolynomialRegression</span><span class="p">(</span><span class="n">degree</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span><span class="n">y_test</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;degree=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">degree</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
</pre></div>


<p>從訓練結果可以發現隨著次方數 degree 的增長模型會變得越複雜。同時對於訓練數據的擬合結果越好。但是這裡必須注意並非越大的 degree 就是越好的，因為隨著模型複雜會有過度擬合的跡象。因此我們必須找出一個適當的 degree 數值並與測試集驗證與評估。目標是訓練集與測試集的 MSE 差距要越小越好。如果我們一昧的追求訓練集的損失最小化，可能會影響到測試集的表現能力導致預測結果變差。</p>
<p><img alt="" src="image/img8-9.png" /></p>
<h2 id="gradient-descent">Gradient descent (梯度下降法)</h2>
<p>接下來我們來討論優化問題的第二種方法，就是梯度下降法。梯度下降不僅限於線性迴歸，在非線性和神經網絡同樣適用。下圖中每一個點是訓練集的樣本 x 軸為輸入值 y 軸為輸出值。也就是平面上每個點 x 都會有一個相對應 y 的輸出，因此我們需要做的事情是為這些點訓練一個模型，使得這條直線能夠盡可能反映出 x 與 y 之間的關係。此外我們都知道在一個二維空間中我們能找到無數條直線，那我們該如何找到這條最佳的直線呢？簡單來說我們的目標是要使得這些訓練資料中的每個樣本點到這一條直線的距離平方和要最小。因此這裡我們將討論該如何使用梯度下降法來最佳化我們的模型。首先我們假設一個直線的方程式是 y = β<sub>0</sub> + β<sub>1</sub>x。那首先我們可以先隨機的給予 β<sub>0</sub> 和 β<sub>1</sub> 一個初始值。並得到下圖中的結果，我們可以發現這一條直線並不能反映出 x 和 y 的關聯性。</p>
<p><img alt="" src="image/img8-10.png" /></p>
<p>如果我們不斷的迭代，每一次的迭代都讓這一條直線朝著更符合數據點的方向移動一點，那麼經過許多次的更新我們就可以得到最佳的結果。簡單來說就是在每次的迭代要更新所有的參數，例如： β<sub>0</sub> 和 β<sub>1</sub>，直到得到最小的 MSE 或是預定的迭代次數。以下的公式就是梯度下降法的表達式。它反映的是每次迭代，我們的 β<sub>0</sub> 和 β<sub>1</sub> 這些參數是如何調整的。我們可以從這個公式得知，他是對損失函數求了某一個特定參數的偏導。這就是所謂的梯度，我們朝著梯度的反方向在更新。然而每一次要更新多大可以依靠 η（(eta) 來控制，因此我們算出來的梯度還會乘上一個學習速率來防止更新步伐太大而導致找不到解。所以 η 的大小要適中以免影響到模型最終的收斂。</p>
<p><img alt="" src="image/img8-11.png" /></p>
<p>此外這個模型如果透過梯度下降法還有一個缺點，那就是當我們的損失函數不是一個凸函數(convex function) 的時候它就會存在許多個最低點，進而導致在我們選擇不同的 β<sub>0</sub> 和 β<sub>1</sub> 作為初始值的時候很可能會收斂於不同的局部最佳解(local optimum)。也就是說我們求得的最佳的模型很有機會是局部最佳解而不是全局最佳解(global optimum)。</p>
<p><img alt="" src="image/img8-12.gif" /></p>
<h2 id="sklearn-sgdregressor">使用 Sklearn SGDRegressor</h2>
<p>Sklearn 提供了 SGDRegressor 並實現了隨機梯度下降學習。你可能會問梯度下降與隨機梯度下降兩者差別在哪？簡單來說一般的梯度下降法是一次用全部訓練集的數據計算損失函數的梯度，然後做一次參數的更新修正。而隨機梯度下降法就是一次跑一個樣本或是小批次樣本，然後算出一次梯度並更新。而所謂的隨機就是在訓練過程中隨機地抽取樣本，所以才會稱為隨機梯度下降法。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="c1"># 隨機產生一個特徵的X與輸出y</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_data</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># 建立 SGDRegressor 並設置超參數</span>
<span class="n">regModel</span> <span class="o">=</span> <span class="n">SGDRegressor</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="c1"># 訓練模型</span>
<span class="n">regModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># 建立測試資料</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">500</span><span class="p">)[:,</span><span class="kc">None</span><span class="p">]</span>
<span class="c1"># 預測測試集</span>
<span class="n">y_test</span><span class="o">=</span><span class="n">regModel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="c1"># 預測訓練集</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">regModel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 視覺化預測結果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span><span class="n">y_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#d62728&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;Loss(MSE)=</span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;color&#39;</span><span class="p">:</span>  <span class="s1">&#39;red&#39;</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="" src="image/img8-13.png" /></p>
<p>本系列教學內容及範例程式都可以從我的 <a href="https://github.com/andy6804tw/2021-13th-ironman">GitHub</a> 取得！</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../7.非監督式學習-降維/" title="[Day 7] 非監督式學習-降維" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  上一頁
                </span>
                [Day 7] 非監督式學習-降維
              </span>
            </div>
          </a>
        
        
          <a href="../9.邏輯迴歸/" title="[Day 9] 邏輯迴歸 (Logistic Regression)" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  下一頁
                </span>
                [Day 9] 邏輯迴歸 (Logistic Regression)
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright © 2021 - 2024 10程式中
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.245445c6.js"></script>
      
        
        
          
          <script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../assets/javascripts/lunr/lunr.ja.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
        <script src="../javascripts/extra.js"></script>
      
        <script src="../javascripts/analytics.js"></script>
      
    
  </body>
</html>